{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6e495-ddb6-4520-9ae9-f8a1b4ebc782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import OneHotEncoder  ##. better to use dummy from pandas \n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "pd.options.display.max_rows = 50\n",
    "## Install xlrd package to load Excel files\n",
    "# conda install openpyxl\n",
    "## conda install xlrd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ddf08-7e04-4d0d-a646-90ec08bbcffb",
   "metadata": {},
   "source": [
    "# ACTIVITY 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ae7a6-2592-4037-b015-8d5d0e81f7e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/Data_Marketing_Customer_Analysis_Round3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Data_Ana \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData/Data_Marketing_Customer_Analysis_Round3.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m Data_Ana_Clean \u001b[38;5;241m=\u001b[39m Data_Ana\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m Data_Ana_Clean\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DA_Env/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DA_Env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DA_Env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DA_Env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DA_Env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DA_Env/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/Data_Marketing_Customer_Analysis_Round3.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "Data_Ana = pd.read_csv('Data/Data_Marketing_Customer_Analysis_Round3.csv')\n",
    "Data_Ana_Clean = Data_Ana.drop(['Unnamed: 0'], axis = 1)\n",
    "Data_Ana_Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66fb0c4-7c85-4dce-aa30-d3b61febe66f",
   "metadata": {},
   "source": [
    "## 1. One Hot/Label Encoding of the categorical variables in the categoricals data frame that you created in Activity 4. ( Hint: check Dropfirst option)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8006766b-a5a1-48d8-8a31-cb824dcdd902",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data = Data_Ana_Clean.select_dtypes('object')\n",
    "categorical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc81da-2aff-4e5b-9963-783167243940",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data = pd.get_dummies(categorical_data)\n",
    "dummy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e1c0d8-63e3-42f7-8e1b-a6891692b039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75e140e1-f591-4e15-80d2-a7c523546b15",
   "metadata": {},
   "source": [
    "## 2. for the first iteration, we will focus on the numericals data (numericals data frame) as our data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb7c463-75e8-4608-ba02-9a35046e5f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = Data_Ana_Clean._get_numeric_data()\n",
    "numerical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822b64bd-2153-49d1-94ac-7bc38dba2665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ea596-807e-44e9-91ce-23a5182abb53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62aa3dec-1d74-40f5-a543-90d883586429",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2b6f4b-68a6-44f9-8ac0-17161a76f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_lifetime_value = numerical_data['customer_lifetime_value']\n",
    "# income = numerical_data['income']\n",
    "# monthly_premium_auto = numerical_data['monthly_premium_auto']\n",
    "# months_since_last_claim = numerical_data['months_since_last_claim']\n",
    "# months_since_policy_inception = numerical_data['months_since_policy_inception']## 3. remove the outliers from the numerical columns.\n",
    "\n",
    "\n",
    "# from scipy.stats import scoreatpercentile as pct\n",
    "# from scipy.stats import iqr\n",
    "\n",
    "# def remove_outliers_costum():\n",
    "#     pct_75 = pct(customer_lifetime_value, 75)  # Calculate percentile 75 using scipy function scoreatpercentile\n",
    "#    pct_25 = pct(customer_lifetime_value, 25)  # Calculate percentile 25 using scipy function scoreatpercentile\n",
    "#    upper_bound = pct_75 + 1.5*iqr(customer_lifetime_value)  # iqr - > Scipy function to calculate the Interquartile Range\n",
    "#    lower_bound = pct_25 - 1.5*iqr(customer_lifetime_value)\n",
    "#    customer_lifetime_value2 = customer_lifetime_value[(customer_lifetime_value <= upper_bound) & (customer_lifetime_value >= lower_bound)]  # Filter out the outliers\n",
    "#    return customer_lifetime_value2\n",
    "\n",
    "\n",
    "# remove_outliers_costum()\n",
    "\n",
    "# NOTE: this works for only singular columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae9dab5-ef59-4a6a-aeab-8e4e84fd06c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for removing the ouliers from all the columns.\n",
    "\n",
    "Q1 = numerical_data.quantile(0.25)\n",
    "Q3 = numerical_data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "numerical_data = numerical_data[~((numerical_data < (Q1 - 1.5 * IQR)) |(numerical_data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "numerical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c15b1e1-004f-4348-ab26-245c5c96e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or simimlarly we can take only the non-outliers values:\n",
    "\n",
    "# numerical_data = numerical_data[((numerical_data > (Q1 - 1.5 * IQR)) |(numerical_data < (Q3 + 1.5 * IQR))).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a11d2-236a-4014-8c03-576f305ad34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkup of some values\n",
    "\n",
    "print(numerical_data['number_of_open_complaints'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764bd42-495d-49c0-a640-27a87d8a31e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. check if there are highly correlated features and drop them if there are any.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94ac1c-2255-4906-95f0-3dab95873fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr = numerical_data.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(9, 7))\n",
    "    ax = sns.heatmap(corr, mask=mask,cmap='coolwarm', vmin=-1,vmax=1,annot=True, square=True)\n",
    "    \n",
    "\n",
    "# RESULT: there are no correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa5fe37-a211-4601-81ab-b1876e515368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fd0b075-0a0f-4dae-b9b7-a8c6b17b4adf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. X-y split (y is the target variable which is the total claim amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ecae21-9821-4361-85bc-b39ca65c6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# first I create a data frame with \n",
    "#. X= all numerical data without the target ('total_claim_amount') and \n",
    "#. y= total_claim_amount.\n",
    "\n",
    "\n",
    "# axis=1  is the X axes and axis=0 is the Y axes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69681a3-25c9-4b1d-b0de-54707d6a90b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numerical_data.drop('total_claim_amount', axis=1)\n",
    "y = numerical_data.total_claim_amount\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4125e-efda-422b-a86f-d10c0570d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7940a-ea2e-4362-b2f9-0507f4da8ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3355cef5-faa8-4fc6-b0fa-7f3d11a01f83",
   "metadata": {},
   "source": [
    "## Train / Test Split - ACTIVITY 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a24bf14-f3a6-4379-a014-73c140d7c5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Now we split the data in TEST and TRAIN sets (in agreement with Hila and Fra  ;)   ).\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30,random_state=123)\n",
    "\n",
    "### test size is the percentage of data taken as test_set (30% test and 70% training, in this case).\n",
    "### you can also write 'train_size =.70' .\n",
    "### random_state = any number you put is the same. this function keep always the same random choice of data taken as sets.\n",
    "###                otherwise it takes always different values when you run it.\n",
    "\n",
    "# check rows and columns\n",
    "X_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37120be-4ea7-4fd5-ac29-3d003167334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fda579e-710f-46af-8028-7b6a1e8d0cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf8a0f48-12d9-49cc-ac70-8844588735fb",
   "metadata": {},
   "source": [
    "## Finding the parameters (mean, variance, from the training set) - ACTIVITY 6\n",
    "\n",
    "## Standardize the data (after the data split) - ACTIVITY 7\n",
    "Standardize the data (after the data split). (done above).\n",
    "Standardize the Data is necessary to bring all the Data to the same levels (to reduce the variables) to be compared each other.\n",
    "(indicateed below as x_test_scaled or x_train_scaled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288c9de5-751b-4bf3-97ad-bd92a43d08ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "std_scaler = StandardScaler().fit(X_train)   # it calculates the z score.\n",
    "\n",
    "X_train_scaled = std_scaler.transform(X_train)   # transforming the data: normalization of all data. \n",
    "\n",
    "\n",
    "X_test_scaled = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a604cd-360e-4ef9-936a-c75015872624",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check rows and columns\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0a2f8b-995f-43d1-8d75-17e43421529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_scaled)\n",
    "print(\"--------\")\n",
    "print(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866b8a9d-009f-4ab2-b654-a34f5c55f815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ced72-5da7-4ce7-a3f9-9041589479a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f977b20-c9c5-4912-952e-a6ae5ef5bfb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ACTIVITY 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4edfbf-32e8-4102-8b09-4c8ad3145792",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6ae554-3587-40d0-b465-3d0d80d0d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c5e577-34fc-41e8-b6c9-5a079982f4a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17db0a3a-5eec-4844-97f8-e2f319e3d1d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Modeling using Statsmodels\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m X_train_const_scaled \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(\u001b[43mX_train_scaled\u001b[49m)     \u001b[38;5;66;03m# adding a constant\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mOLS(y_train, X_train_const_scaled)\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m      6\u001b[0m predictions_train \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train_const_scaled) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Modeling using Statsmodels\n",
    "\n",
    "X_train_const_scaled = sm.add_constant(X_train_scaled)     # adding a constant\n",
    "\n",
    "model = sm.OLS(y_train, X_train_const_scaled).fit()\n",
    "predictions_train = model.predict(X_train_const_scaled) \n",
    "\n",
    "X_test_const_scaled = sm.add_constant(X_test_scaled)       # adding a constant\n",
    "predictions_test = model.predict(X_test_const_scaled) \n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c15fe1d1-cbe8-46d2-8832-3f3d0c221e17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictions_test\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions_test' is not defined"
     ]
    }
   ],
   "source": [
    "predictions_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf18b498-78a8-4893-b069-c07e996e7c69",
   "metadata": {},
   "source": [
    "### R-SQUARED VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edef70f-58a1-44e5-8dfa-bb857cd2e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display adjusted R-squared\n",
    "# difference between the model and the real values (the training data set).\n",
    "# to check the validity of the model.\n",
    "\n",
    "print(model.rsquared_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23aeb6d-c8de-4e1a-a173-08c2d22d3526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487d5c4f-387f-4703-bf58-b995fa27bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f89410-1548-496e-b06d-00a8064503d8",
   "metadata": {},
   "source": [
    "## Apply linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211eb358-a845-44c5-bf36-bc54490a116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (This is a Supervised Training. So you need the X_train_scaled (all standardized training data) and the values used as target, which are the y_train).\n",
    "\n",
    "\n",
    "model = LinearRegression()            # model\n",
    "model.fit(X_train_scaled, y_train)    # model train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0091f04-966d-47e9-87eb-402d644ebed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b6984a-6f91-47d8-8cce-f21cf704391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78d30a-ef59-44a5-87ad-aa5d1a75a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then you get the following model that can predict new data.\n",
    "# NOTE: the values in the equation below come from the model.coef_ and the model.intercept_  \n",
    "\n",
    "# target_donation = 1.34* avg_fam_income  -0.41 * pobc2   +5.45 * avggift  -0.48 * med_home_val_transformed  + 15.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba7a09-2c81-4aae-a919-d9e64adfa38b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0afa4c0-e7c3-46df-903d-7eb409b4908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following 'predict function' is running the equation that is above (the model for predict new data).\n",
    "\n",
    "y_pred=model.predict(X_test_scaled)          # model prediction\n",
    "\n",
    "y_pred_train=model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27956462-596e-4ca7-938a-963810fecdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e24f218-1638-480c-ab48-af86672b4c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7df183f-d200-42fa-aa87-f2bda791b8f4",
   "metadata": {},
   "source": [
    "## Model Interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a45591-0da4-460d-b9d8-6e1ea9df3403",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b23a8-c2ec-4a89-962d-68221bf5e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1878f324-84b2-4039-b6b5-f8a2ed5a9e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = y_test - y_pred\n",
    "residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efafa975-41ee-4b6b-a4a4-10464c288f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c167a2d-b400-4413-8924-4b04a11a38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame({\"y_test\":y_test,\"y_pred\":y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697be3ab-1607-43a9-b8cc-77ca26ec5365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an scatter plot y_pred vs y\n",
    "# What kind of plot you will get if all the all the predictions are ok?\n",
    "# A stright line\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(14,4))\n",
    "ax[0].plot(y_pred, y_test, 'o')\n",
    "ax[0].set_xlabel(\"y_test\")\n",
    "ax[0].set_ylabel(\"y_pred\")\n",
    "ax[0].set_title(\"Test Set -Predicted vs real\")\n",
    "\n",
    "# Get a histogram of the residuals ie: y - y_pred.  Homoscdasticity\n",
    "# It resembles a normal distribution?\n",
    "ax[1].hist(residual)        ## residual = (y_test - y_pred)\n",
    "ax[1].set_xlabel(\"Test y-y_pred\")\n",
    "ax[1].set_title(\"Test Set Residual histogram\")\n",
    "\n",
    "ax[2].plot(y_pred,residual,\"o\")\n",
    "ax[2].set_xlabel(\"predicted\")\n",
    "ax[2].set_ylabel(\"residuals\")\n",
    "ax[2].set_title(\"Residuals by Predicted\")\n",
    "ax[2].plot(y_pred,np.zeros(len(y_pred)),linestyle='dashed')\n",
    "\n",
    "# Explanation of the graphs are in the file: 'Notebook_Code_Along_Intro_To_Pandas_Healthcare For_All_Modeling'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ef7f8a-b01d-480d-8121-4ffc1397bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: when a model is really good:\n",
    "####   - first graph: model works in prediction when it result a linear regression between the predict and the test values.\n",
    "####   - second graph: histogram; perfect if normal distribution of the errors (y_test-y_pred).\n",
    "####   - last graph: plotting the 'residuals' with the 'predict', more the values are around the line more it means that the residuals (errors) are zero (zero difference between prediction and real values), and more the model is good.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc91519-1f1d-4dcb-8612-c6b55ba309c2",
   "metadata": {},
   "source": [
    "## Seaborn alternative to check the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09373036-a6dc-41e0-8cea-52b17d97881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='y_pred',y='y_test', data=result, scatter_kws={\"color\": \"salmon\"}, line_kws={\"color\": \"purple\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b57d7-670a-4bea-8b3c-12e8e01c6efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1989d89f-7cf2-4c8a-beed-014ddca3a2f2",
   "metadata": {},
   "source": [
    "## MSE: Mean Squared Error\n",
    "## MAE: Mean Absolute Error\n",
    "## RMSE: Root Mean Square Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d188b-6bcb-4e51-bef7-eae5927f1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "\n",
    "print(mse(y_test,y_pred))\n",
    "print(mae(y_test,y_pred))\n",
    "print(np.sqrt(mse(y_test,y_pred)))   ## in Seaborn doesn't exist RMSE so we calculate it with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28c217-e84c-4b00-b640-bd8dc621ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on the train set\n",
    "\n",
    "mse(y_train,y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c84cd3-ebab-474e-8637-8ad4fdeb4910",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae(y_train,y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f7c7ac-806f-40f5-b6f1-0d066179bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if the errors in train and test sets are similar the models are ok."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ece42b5-8c55-4e0f-80c2-fa45a2ccec37",
   "metadata": {},
   "source": [
    "# R2: Sample R-Squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dfbc22-f419-494c-8b08-16430ae292c8",
   "metadata": {},
   "source": [
    "R2: Sample R-Squared\n",
    "- Provides a way to compare the performance of several models\n",
    "- Provides a measurement of the “explanatory” power of a model (shows how much variance of y can be explained by the independent features) \n",
    "- Compares the variance of your model’s errors against the “mean model” (model for which all the predictions are the mean of the dependent variable)\n",
    "- Increases with every independent feature you add\n",
    "- more the R2 value is close to 1 and more the model is perfect.\n",
    "\n",
    "\n",
    "note: see presentation week4 day2 (Linear Regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c1791b-f583-4592-972c-626040a58552",
   "metadata": {},
   "source": [
    "R^2 = (SST - SSE)/SST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6494dd-546a-496f-8022-ebb6219d5ad9",
   "metadata": {},
   "source": [
    "R^2 = 1-SSE/SST\n",
    "\n",
    "more the R2 value is close to 1 and more the model is perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e593dd7-5a23-418b-98c6-a395607cfa7d",
   "metadata": {},
   "source": [
    "SSE = sum of the square of the errors\n",
    "SST = total sum of squares explained by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d333a-8b67-4925-be75-eacfa112322e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eb2a63-0802-4b4b-81a3-047a9829b7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2=r2_score(y_test,y_pred)\n",
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1fbae-0d9b-4ab9-991a-f56a3ce42eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_test=model.score(X_test_scaled,y_test)\n",
    "R2_train=model.score(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74365ae2-8e23-45e7-8a9a-90ca51971526",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead6160-ae9f-4b8c-b6d6-8dc0a5870f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04532b30-de11-4036-8b6e-a3d44b26553b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c598311d-8cfe-48de-9dfa-5a1d30c65090",
   "metadata": {},
   "source": [
    "### adjusted R2:\n",
    "\n",
    "Provides a measurement of the “explanatory” power of a model taking into account the number of independent features used by the model.\n",
    "Only increases if the inclusion of a new feature improves the model’s performance.\n",
    "- it is used for Sklearn since it doesn't have R2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507fb09-73c0-4ddd-a903-f904b41c93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_R2_test = 1 - (1-R2)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "adjusted_R2_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6054ebfa-e42d-433e-bbcf-b45406802f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32042348-ef9b-4068-bb36-e951e56ca411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec7beac1-3727-4dcd-ad02-73474df309d6",
   "metadata": {},
   "source": [
    "# Feature Importances\n",
    "#### it helps to check which variable is more affecting the model. It means, when little changes of the variable bring bigger changes to the result of the model equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782a1c1-98ca-4e99-8f88-e4e3dba2f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance': abs(model.coef_)\n",
    "})\n",
    "features_importances = features_importances.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8e8b9-7065-4528-addb-98008fd1c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aeb7f0-aa3a-4eb0-b784-8352328babd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=features_importances['Attribute'], height=features_importances['Importance'], color='#087E8B')\n",
    "plt.title('Feature importances obtained from coefficients', size=20)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a6960c-fb5c-4b01-84fb-cd09e5193913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7fd11f-d0b2-4c15-9c65-34e0101aba93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
